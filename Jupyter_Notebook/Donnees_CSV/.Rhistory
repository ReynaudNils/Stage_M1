A_posterior_beta <- dbeta(x_beta, shape1 = 281, shape2 = 1623)
plot(A_prior_beta, col='red', type='l', xlab = pi)
lines(A_posterior_beta, col='blue')
abline(v=(125 + 134 + 21) / (2*950), col='green')
legend("topright", legend=c("a priori", "a posteriori","estimateur de vraisemblance"), bty='n', box.lwd = 1, col=c('red','blue','green'))
x = seq(0, 1, length.out = 500)
plot(x, dbeta(x, 1, 3),type = 'l',col = 1)
lines(x, dbeta(x, 281, 1623), col = 2)
abline(v=(125+134+21)/(2*950), col = 3)
x_beta <- seq(0, 1, length.out=500)
A_prior_beta <- dbeta(x_beta, shape1 = 1, shape2 = 3)
A_posterior_beta <- dbeta(x_beta, shape1 = 281, shape2 = 1623)
plot(A_prior_beta, col='red', type='l', xlab = pi)
lines(A_posterior_beta, col='blue')
abline(v=(125+134+21)/(2*950), col = 3)
legend("topright", legend=c("a priori", "a posteriori","estimateur de vraisemblance"), bty='n', box.lwd = 1, col=c('red','blue','green'))
x_beta <- seq(0, 1, length.out=500)
A_prior_beta <- dbeta(x_beta, shape1 = 1, shape2 = 3)
A_posterior_beta <- dbeta(x_beta, shape1 = 281, shape2 = 1623)
plot(A_prior_beta, col='red', type='l')
lines(A_posterior_beta, col='blue')
abline(v=(125+134+21)/(2*950), col = 3)
legend("topright", legend=c("a priori", "a posteriori","estimateur de vraisemblance"), bty='n', box.lwd = 1, col=c('red','blue','green'))
x_beta <- seq(0, 1, length.out=500)
A_prior_beta <- dbeta(x_beta, shape1 = 1, shape2 = 3)
A_posterior_beta <- dbeta(x_beta, shape1 = 281, shape2 = 1623)
plot(x_beta, A_prior_beta, col='red', type='l')
lines(A_posterior_beta, col='blue')
abline(v=(125+134+21)/(2*950), col = 3)
legend("topright", legend=c("a priori", "a posteriori","estimateur de vraisemblance"), bty='n', box.lwd = 1, col=c('red','blue','green'))
x_beta <- seq(0, 1, length.out=500)
A_prior_beta <- dbeta(x_beta, shape1 = 1, shape2 = 3)
A_posterior_beta <- dbeta(x_beta, shape1 = 281, shape2 = 1623)
plot(x_beta, A_prior_beta, col='red', type='l')
lines(x_beta, A_posterior_beta, col='blue')
abline(v=(125+134+21)/(2*950), col = 3)
legend("topright", legend=c("a priori", "a posteriori","estimateur de vraisemblance"), bty='n', box.lwd = 1, col=c('red','blue','green'))
x_beta <- seq(0, 1, length.out=500)
A_prior_beta <- dbeta(x_beta, shape1 = 1, shape2 = 3)
A_posterior_beta <- dbeta(x_beta, shape1 = 281, shape2 = 1623)
plot(x_beta, A_prior_beta, col='red', type='l')
lines(x_beta, A_posterior_beta, col='blue')
abline(v=(125+134+21)/(2*950), col = 3)
Estimateur_N = (125*155) / (21)
Estimateur_N
N = 923
pi = 0.15
Estimateur_N = c()
for (j in 1:100){
echantillon = Modèle_M(N, pi)
while (echantillon[3] == 0) {echantillon = Modèle_M(N, pi)} ##Dans l'estimateur N  il faut diviser par $C_{21}$ donc il faut s'assurer que ce terme est non nul
Estimateur_N = c(Estimateur_N, echantillon[1] * ((echantillon[2] + echantillon[3]) / (echantillon[3])))
}
N = 923
pi = 0.15
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(N, pi)
while (echantillon[3] == 0) {echantillon = Modele_M(N, pi)} ##Dans l'estimateur N  il faut diviser par $C_{21}$ donc il faut s'assurer que ce terme est non nul
Estimateur_N = c(Estimateur_N, echantillon[1] * ((echantillon[2] + echantillon[3]) / (echantillon[3])))
}
N = 923
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(N, 0.15)
while (echantillon[3] == 0) {echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N  il faut diviser par $C_{21}$ donc il faut s'assurer que ce terme est non nul
Estimateur_N = c(Estimateur_N, echantillon[1] * ((echantillon[2] + echantillon[3]) / (echantillon[3])))
}
my_rbinomiale <- function(n, N, pi){
U=runif(n)
F_k=pbinom(0:N, size=N, prob=pi)
return(findInterval(U, F_k))
}
n = 1000
N = 125
pi = 0.15
freq_theo = dbinom(0:N, N, pi)
C1 <- my_rbinomiale(n, N, pi)
resultats <- data.frame(n=1:N, valeurs=factor(C1, levels = 0:N))
freq_emp <- c()
for (k in 0:N){
freq_emp <- c(freq_emp, mean(C1==k))
}
freq_binomiale <- tibble( x=0:N, freq_emp=freq_emp, freq_theo=freq_theo)
# Représentation graphique
ggplot(freq_binomiale) +
aes(x = x) +
geom_col(mapping = aes(y = freq_emp),
width = 0.2, fill = "blue") +
geom_point(aes(y = freq_theo),
shape = 3, col = "red", size = 3) +
labs(y = "Comparaison_Frequence", x = "Nombre de succès")
Modele_M <- function(N, pi){
C1 <- my_rbinomiale(1, N, pi)
C20 <- my_rbinomiale(1, N-C1, pi)
C21 <- my_rbinomiale(1, C1, pi)
return(c(C1,C20,C21))
}
Estimateur_pi = (125 + 134 + 21) / (2*950)
Estimateur_pi
x_beta <- seq(0, 1, length.out=500)
A_prior_beta <- dbeta(x_beta, shape1 = 1, shape2 = 3)
A_posterior_beta <- dbeta(x_beta, shape1 = 281, shape2 = 1623)
plot(x_beta, A_prior_beta, col='red', type='l')
lines(x_beta, A_posterior_beta, col='blue')
abline(v=(125+134+21)/(2*950), col = 3)
Estimateur_N = (125*155) / (21)
Estimateur_N
N = 923
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(N, 0.15)
while (echantillon[3] == 0) {echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N  il faut diviser par $C_{21}$ donc il faut s'assurer que ce terme est non nul
Estimateur_N = c(Estimateur_N, echantillon[1] * ((echantillon[2] + echantillon[3]) / (echantillon[3])))
}
Biais_relatif = (mean(Estimateur_N) - N)/N
Biais_relatif
N = seq(100, 1000, 10)
Biais_relatif = c()
for (k in N){
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(N, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - k)/k)
}
N = seq(100, 1000, 10)
biais_relatif = c()
for(i in N){
estim_N = c()
for(k in 1:100){
gener = Modele_M(i, 0.15) ##on génère
while(gener[[3]] == 0){ gener[3] = Modele_M(i, 0.15)[3]}
##comme on divise par C_{21} on est obligé de s'assurer que gener[3]=C_{21} !=0
estim_N = c(estim_N, gener[[1]]*(gener[[2]]+gener[[3]])/gener[[3]]) #C_{2}=gener[2]+gener[3]
}
biais_relatif = c(biais_relatif, (mean(estim_N) - i)/i)
}
plot(N, biais_relatif)
N = seq(100, 1000, 10)
Biais_relatif = c()
for (k in N){
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(N, 0.15)
while (echantillon[3] == 0) {
echantillon [3] = Modele_M(N, 0.15)[3]} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - k)/k)
}
N = seq(100, 1000, 10)
Biais_relatif = c()
for (k in N){
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(k, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - k)/k)
}
N = seq(100, 1000, 10)
Biais_relatif = c()
for (i in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(i, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - k)/k)
}
N = seq(100, 1000, 10)
Biais_relatif = c()
for (i in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(i, 0.15)
while (echantillon[[3]] == 0) {
echantillon [3] = Modele_M(N, 0.15)[3]} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[[1]] * (echantillon[[2]] + echantillon[[3]])/(echantillon[[3]])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - k)/k)
}
N = seq(100, 1000, 10)
Biais_relatif = c()
for(i in N){
Estimateur_N = c()
for(k in 1:100){
gener = Modele_M(i, 0.15) ##on génère
while(gener[[3]] == 0){ gener[3] = Modele_M(i, 0.15)[3]}
##comme on divise par C_{21} on est obligé de s'assurer que gener[3]=C_{21} !=0
Estimateur_N = c(Estimateur_N, gener[[1]]*(gener[[2]]+gener[[3]])/gener[[3]]) #C_{2}=gener[2]+gener[3]
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - i)/i)
}
plot(N, Biais_relatif)
N = seq(100, 1000, 10)
Biais_relatif = c()
for (i in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(i, 0.15)
while (echantillon[[3]] == 0) {
echantillon [3] = Modele_M(i, 0.15)[3]} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[[1]] * (echantillon[[2]] + echantillon[[3]])/(echantillon[[3]])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - k)/k)
}
plot(N, Biais_relatif)
N = seq(100, 1000, 10)
Biais_relatif = c()
for (i in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(i, 0.15)
while (echantillon[[3]] == 0) {
echantillon [3] = Modele_M(i, 0.15)[3]} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[[1]] * (echantillon[[2]] + echantillon[[3]])/(echantillon[[3]])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - i)/i)
}
plot(N, Biais_relatif)
N = seq(100, 1000, 10)
Biais_relatif = c()
for (i in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(i, 0.15)
while (echantillon[[3]] == 0) {
echantillon = Modele_M(i, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[[1]] * (echantillon[[2]] + echantillon[[3]])/(echantillon[[3]])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - i)/i)
}
plot(N, Biais_relatif)
N = seq(100, 1000, 10)
Biais_relatif = c()
for (j in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(j, 0.15)
while (echantillon[[3]] == 0) {
echantillon = Modele_M(j, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[[1]] * (echantillon[[2]] + echantillon[[3]])/(echantillon[[3]])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - j)/j)
}
plot(N, Biais_relatif)
N = seq(100, 1000, 10)
Biais_relatif = c()
for (j in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(j, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(j, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - j)/j)
}
plot(N, Biais_relatif)
N = 923
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(N, 0.15)
while (echantillon[3] == 0) {echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N  il faut diviser par $C_{21}$ donc il faut s'assurer que ce terme est non nul
Estimateur_N = c(Estimateur_N, echantillon[1] * ((echantillon[2] + echantillon[3]) / (echantillon[3])))
}
Biais_relatif = (mean(Estimateur_N) - N)/N
Biais_relatif
N = 923
Estimateur_N = c()
for (j in 1:100){
echantillon = Modele_M(N, 0.15)
while (echantillon[3] == 0) {echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N  il faut diviser par $C_{21}$ donc il faut s'assurer que ce terme est non nul
Estimateur_N = c(Estimateur_N, echantillon[1] * ((echantillon[2] + echantillon[3]) / (echantillon[3])))
}
Biais_relatif = (mean(Estimateur_N) - N)/N
Biais_relatif
N = seq(100, 1000, 10)
Biais_relatif = c()
for (j in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(j, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(j, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - j)/j)
}
plot(N, Biais_relatif)
`
N = seq(100, 1000, 10)
Biais_relatif = c()
for (j in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(j, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(j, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - j)/j)
}
plot(N, Biais_relatif)
N = seq(100, 1000, 10)
Biais_relatif = c()
for (j in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(j, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(j, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - j)/j)
}
plot(N, Biais_relatif)
N = 923
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(N, 0.15)
while (echantillon[3] == 0) {echantillon = Modele_M(N, 0.15)} ##Dans l'estimateur N  il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, echantillon[1] * ((echantillon[2] + echantillon[3]) / (echantillon[3])))
}
Biais_relatif = (mean(Estimateur_N) - N)/N
Biais_relatif
N = seq(100, 1000, 10)
Biais_relatif = c()
for (j in N){
Estimateur_N = c()
for (k in 1:100){
echantillon = Modele_M(j, 0.15)
while (echantillon[3] == 0) {
echantillon = Modele_M(j, 0.15)} ##Dans l'estimateur N il faut diviser par $C_{21}$ donc faire en sorte que ce terme soit non nul
Estimateur_N = c(Estimateur_N, (echantillon[1] * (echantillon[2] + echantillon[3])/(echantillon[3])))
}
Biais_relatif = c(Biais_relatif, (mean(Estimateur_N) - j)/j)
}
plot(N, Biais_relatif)
library(zipfR)
library(zipfR)
ZM = Inre("zm", alpha = 2/3, B = 0.1)
zmsample = rInre(ZM, n=100)
help(Inre)
??Inre
??rInre
ZM = Inre("zm", alpha = 2/3, B = 0.1)
ZM = lnre("zm", alpha = 2/3, B = 0.1)
zmsample = rlnre(ZM, n=100)
zmnumeric = as.numeric(as.character(zmsample))
plot(zmnumeric)
library(zipfR)
ZM = lnre("zm", alpha = 1.5, B = 0.1)
zmsample = rlnre(ZM, n=100)
zmnumeric = as.numeric(as.character(zmsample))
plot(zmnumeric)
library(zipfR)
ZM = lnre("zm", alpha = 1.5, B = 0.1)
zmsample = rlnre(ZM, n=1000)
zmnumeric = as.numeric(as.character(zmsample))
plot(zmnumeric)
zmsample = rlnre(ZM, n=500)
library(zipfR)
ZM = lnre("zm", alpha = 1.5, B = 0.1)
zmsample = rlnre(ZM, n=500)
zmnumeric = as.numeric(as.character(zmsample))
plot(zmnumeric)
library(zipfR)
ZM = lnre("zm", alpha = 1.5, B = 0.1)
zmsample = rlnre(ZM, n=100)
zmnumeric = as.numeric(as.character(zmsample))
plot(zmnumeric)
library(ggplot2)
library(dplyr)
library(themes)
library(gganimate)
word_count <- # Data frame containing words and their frequency
colnames(word_count) <- c("word", "count")
alpha <- 1 # Change it needed
word_count <- word_count %>%
mutate(word = factor(word, levels = word),
rank = row_number(),
zipfs_freq = ifelse(rank == 1, count, dplyr::first(count) / rank^alpha))
zipfs_plot <- ggplot(word_count, aes(x = rank, y = count)) +
geom_point(aes(color = "observed")) +
theme_bw() +
geom_point(aes(y = zipfs_freq, color = "theoretical")) +
transition_reveal(count, rank) +
labs(x = "rank", y = "count", title = "Zipf's law visualization") +
scale_colour_manual(name = "Word count", values=c("theoretical" = "red", "observed" = "black")) +
theme(legend.position = "top")
zipfs_animation <- animate(p)
data(BCI)
data(meaudret)
vegan
library(vegan)
plot(1:10810)
source("C:/Users/nilsr/Desktop/PRE/ZM-Fitting.R")
getwd()
setwd('C:/Users/nilsr/Desktop/PRE/Stage_M1/Jupyter_Notebook/Donnees_CSV')
install.packages("dplyr")
desc <- dplyr::desc
library(dplyr)
Species <- read.csv('Especes.csv')
Genera <- read.csv('Especes2.csv')
Species$Rank<-rank( desc (Species$Images_Plante))
Genera$Rank<-rank( desc (Genera$Images_Genre))
Species
Genera
#R code Species
set.seed(8)
q.hats <- c()
beta.hats <- c()
ss.hats <- c()
for (bx in 1:10) {
q.mc <- c()
res.sq.mc <- c()
for (b in 1:300) {
q.b <- runif(1, 0, 100)
q.mc <- append(q.mc, q.b)
print(length(q.b))
print(q.b)
print(length(Species$Rank))
#print(Species$Rank)
res.sq.b <- sum( lm(log(Species$Images_Plante) ~ log(Species$Rank +q.b))$residuals^2)
res.sq.mc <- append(res.sq.mc, res.sq.b)
}
res.q.mc.dat <- data.frame(q.mc,res.sq.mc)
q.hat <- res.q.mc.dat[which(res.q.mc.dat$res.sq.mc == min(res.q.mc.dat$res.sq.mc) ),]$q.mc
beta.hat <- lm(log(Species$Images_Plante) ~ log(Species$Rank + q.hat))$coefficients[2]
ss.hat <- sum( lm(log(Species$Images_Plante) ~ log(Species$Rank + q.hat))$residuals^2)
q.hats <- append(q.hats, q.hat)
beta.hats <- append(beta.hats, beta.hat)
ss.hats <- append(ss.hats, ss.hat)
qbeta.dat <- data.frame(q.hats,beta.hats)
}
fit <- lm( log(Species$Images_Plante) ~ log(Species$Rank + mean(q.hats)))
fit
q <- signif(mean(q.hats), 4)
z <- signif(fit$coef[[2]], 4) * (-1)
q
z
plot(Species$Rank +mean(q.hats), Species$Images_Plante, type="l", log="xy")
title(main="Plot pour les espèces avec le q optimisé")
plot(Species$Rank +mean(q.hats), Species$Images_Plante, type="l")
title(main="Plot pour les espèces avec le q optimisé")
plot(Species$Rank +mean(q.hats), Species$Images_Plante, type="l", log="xy")
title(main="Plot pour les espèces avec le q optimisé")
#Comparons les courbes
Ordonnes <- Species$Images_Plante/306146
plot(Species$Rank, Ordonnes)
Species <- read.csv('Especes.csv')
Genera <- read.csv('Especes2.csv')
Species$Rank<-rank( desc (Species$Images_Plante))
Genera$Rank<-rank( desc (Genera$Images_Genre))
Species
Genera
#R code Species
set.seed(8)
q.hats <- c()
beta.hats <- c()
ss.hats <- c()
for (bx in 1:10) {
q.mc <- c()
res.sq.mc <- c()
for (b in 1:300) {
q.b <- runif(1, 0, 100)
q.mc <- append(q.mc, q.b)
print(length(q.b))
print(q.b)
print(length(Species$Rank))
#print(Species$Rank)
res.sq.b <- sum( lm(log(Species$Images_Plante/306146) ~ log(Species$Rank +q.b))$residuals^2)
res.sq.mc <- append(res.sq.mc, res.sq.b)
}
res.q.mc.dat <- data.frame(q.mc,res.sq.mc)
q.hat <- res.q.mc.dat[which(res.q.mc.dat$res.sq.mc == min(res.q.mc.dat$res.sq.mc) ),]$q.mc
beta.hat <- lm(log(Species$Images_Plante/306146) ~ log(Species$Rank + q.hat))$coefficients[2]
ss.hat <- sum( lm(log(Species$Images_Plante/306146) ~ log(Species$Rank + q.hat))$residuals^2)
q.hats <- append(q.hats, q.hat)
beta.hats <- append(beta.hats, beta.hat)
ss.hats <- append(ss.hats, ss.hat)
qbeta.dat <- data.frame(q.hats,beta.hats)
}
fit <- lm( log(Species$Images_Plante/306146) ~ log(Species$Rank + mean(q.hats)))
fit
q <- signif(mean(q.hats), 4)
z <- signif(fit$coef[[2]], 4) * (-1)
q
z
plot(Species$Rank +mean(q.hats), Species$Images_Plante/306146, type="l", log="xy")
title(main="Plot pour les espèces avec le q optimisé")
plot(Species$Rank +mean(q.hats), Species$Images_Plante/306146, type="l")
plot(Species$Rank +mean(q.hats), Species$Images_Plante/306146, type="l")
title(main="Plot pour les espèces avec le q optimisé")
lines(Species$Rank, Species$Images_Plante/306146)
plot(Species$Rank +mean(q.hats), Species$Images_Plante/306146, type="l")
title(main="Plot pour les espèces avec le q optimisé")
lines(Species$Rank, Species$Images_Plante/306146, col="red")
plot(Species$Rank +mean(q.hats), Species$Images_Plante/306146, type="l", log="xy")
help(zipfR)
??zipfR
install.packages("zipfR")
